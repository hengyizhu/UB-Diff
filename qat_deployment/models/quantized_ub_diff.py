"""
é‡åŒ–ç‰ˆæœ¬çš„UB-Diffæ¨¡å‹

ä¸“é—¨ä¸ºæ ‘è“æ´¾éƒ¨ç½²ä¼˜åŒ–çš„é‡åŒ–æ¨¡å‹ï¼Œé›†æˆæ”¹è¿›çš„é‡åŒ–ç­–ç•¥
"""

import torch
import torch.nn as nn
import torch.quantization as quant
from typing import Optional, Tuple, Dict, Any
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„åˆ°sys.path
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(os.path.dirname(current_dir))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from model.components import (
    VelocityDecoder, 
    SeismicDecoder,
    Unet1D,
    GaussianDiffusion1DDefault,
    cosine_beta_schedule
)
from model.components.decoder import LatentProjector

# å¯¼å…¥æ”¹è¿›çš„é‡åŒ–åŠŸèƒ½
from .improved_quantization import (
    analyze_model_quantizability,
    apply_improved_quantization,
    create_quantization_report,
    ImprovedQuantizationConfig
)


class Conv1DWrapper(nn.Module):
    """1Då·ç§¯åŒ…è£…å™¨ï¼Œè½¬æ¢ä¸º2Då·ç§¯ä»¥è·å¾—æ›´å¥½çš„é‡åŒ–æ”¯æŒ"""
    
    def __init__(self, conv1d_layer):
        super().__init__()
        # ä¿å­˜åŸå§‹å‚æ•°
        in_channels = conv1d_layer.in_channels
        out_channels = conv1d_layer.out_channels
        kernel_size = conv1d_layer.kernel_size[0]
        stride = conv1d_layer.stride[0]
        padding = conv1d_layer.padding[0]
        dilation = conv1d_layer.dilation[0]
        groups = conv1d_layer.groups
        bias = conv1d_layer.bias is not None
        
        # åˆ›å»ºç­‰æ•ˆçš„2Då·ç§¯
        self.conv2d = nn.Conv2d(
            in_channels=in_channels,
            out_channels=out_channels,
            kernel_size=(1, kernel_size),
            stride=(1, stride),
            padding=(0, padding),
            dilation=(1, dilation),
            groups=groups,
            bias=bias
        )
        
        # å¤åˆ¶æƒé‡
        with torch.no_grad():
            # æƒé‡: (out, in, k) -> (out, in, 1, k)
            self.conv2d.weight.copy_(conv1d_layer.weight.unsqueeze(2))
            if bias:
                self.conv2d.bias.copy_(conv1d_layer.bias)
    
    def forward(self, x):
        # è¾“å…¥: (B, C, L) -> (B, C, 1, L)
        if x.dim() == 3:
            x = x.unsqueeze(2)
        
        # 2Då·ç§¯
        x = self.conv2d(x)
        
        # è¾“å‡º: (B, C, 1, L) -> (B, C, L)
        return x.squeeze(2)


def convert_conv1d_to_conv2d(module):
    """é€’å½’è½¬æ¢æ¨¡å—ä¸­çš„æ‰€æœ‰1Då·ç§¯ä¸º2Då·ç§¯"""
    converted_count = 0
    
    for name, child in list(module.named_children()):
        if isinstance(child, nn.Conv1d):
            # è½¬æ¢1Då·ç§¯
            setattr(module, name, Conv1DWrapper(child))
            converted_count += 1
        else:
            # é€’å½’å¤„ç†å­æ¨¡å—
            converted_count += convert_conv1d_to_conv2d(child)
    
    return converted_count


class QuantizedDecoder(nn.Module):
    """é‡åŒ–çš„è§£ç å™¨æ¨¡å—
    
    åŒ…å«é€Ÿåº¦è§£ç å™¨å’Œåœ°éœ‡è§£ç å™¨çš„é‡åŒ–ç‰ˆæœ¬
    """
    
    def __init__(self, 
                 encoder_dim: int = 512,
                 velocity_channels: int = 1,
                 seismic_channels: int = 5,
                 velocity_latent_dim: int = 128,
                 seismic_latent_dim: int = 640,
                 seismic_h: int = 1000,
                 seismic_w: int = 70,
                 quantize_velocity: bool = True,
                 quantize_seismic: bool = True):
        """
        Args:
            encoder_dim: ç¼–ç å™¨è¾“å‡ºç»´åº¦
            velocity_channels: é€Ÿåº¦åœºé€šé“æ•°
            seismic_channels: åœ°éœ‡æ•°æ®é€šé“æ•°
            velocity_latent_dim: é€Ÿåº¦è§£ç å™¨æ½œåœ¨ç»´åº¦
            seismic_latent_dim: åœ°éœ‡è§£ç å™¨æ½œåœ¨ç»´åº¦
            seismic_h, seismic_w: åœ°éœ‡æ•°æ®å°ºå¯¸
            quantize_velocity: æ˜¯å¦é‡åŒ–é€Ÿåº¦è§£ç å™¨
            quantize_seismic: æ˜¯å¦é‡åŒ–åœ°éœ‡è§£ç å™¨
        """
        super(QuantizedDecoder, self).__init__()
        
        self.quantize_velocity = quantize_velocity
        self.quantize_seismic = quantize_seismic
        
        # ä¸ºæ¯ä¸ªè·¯å¾„åˆ›å»ºç‹¬ç«‹çš„é‡åŒ–å±‚
        self.velocity_quant = quant.QuantStub()
        self.velocity_dequant = quant.DeQuantStub()
        self.seismic_quant = quant.QuantStub()
        self.seismic_dequant = quant.DeQuantStub()
        
        # æ½œåœ¨ç©ºé—´æŠ•å½±å™¨
        self.velocity_projector = LatentProjector(encoder_dim, velocity_latent_dim)
        self.seismic_projector = LatentProjector(encoder_dim, seismic_latent_dim)
        
        # è§£ç å™¨
        self.velocity_decoder = VelocityDecoder(
            latent_dim=velocity_latent_dim,
            out_channels=velocity_channels
        )
        self.seismic_decoder = SeismicDecoder(
            latent_dim=seismic_latent_dim,
            out_channels=seismic_channels,
            origin_h=seismic_h,
            origin_w=seismic_w
        )
        
    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """å‰å‘ä¼ æ’­
        
        Args:
            x: æ½œåœ¨è¡¨ç¤º (B, encoder_dim, 1, 1)
            
        Returns:
            (velocity, seismic): è§£ç åçš„é€Ÿåº¦åœºå’Œåœ°éœ‡æ•°æ®
        """
        # é€Ÿåº¦è§£ç è·¯å¾„
        if self.quantize_velocity:
            x_v = self.velocity_quant(x)
            z_v = self.velocity_projector(x_v)
            velocity = self.velocity_decoder(z_v)
            velocity = self.velocity_dequant(velocity)
        else:
            z_v = self.velocity_projector(x)
            velocity = self.velocity_decoder(z_v)
        
        # åœ°éœ‡è§£ç è·¯å¾„  
        if self.quantize_seismic:
            x_s = self.seismic_quant(x)
            z_s = self.seismic_projector(x_s)
            seismic = self.seismic_decoder(z_s)
            seismic = self.seismic_dequant(seismic)
        else:
            z_s = self.seismic_projector(x)
            seismic = self.seismic_decoder(z_s)
        
        return velocity, seismic
    
    def freeze_velocity_path(self) -> None:
        """å†»ç»“é€Ÿåº¦è§£ç è·¯å¾„"""
        for param in self.velocity_projector.parameters():
            param.requires_grad = False
        for param in self.velocity_decoder.parameters():
            param.requires_grad = False
        print("é€Ÿåº¦è§£ç è·¯å¾„å·²å†»ç»“")
    
    def freeze_seismic_path(self) -> None:
        """å†»ç»“åœ°éœ‡è§£ç è·¯å¾„"""
        for param in self.seismic_projector.parameters():
            param.requires_grad = False
        for param in self.seismic_decoder.parameters():
            param.requires_grad = False
        print("åœ°éœ‡è§£ç è·¯å¾„å·²å†»ç»“")
    
    def unfreeze_velocity_path(self) -> None:
        """è§£å†»é€Ÿåº¦è§£ç è·¯å¾„"""
        for param in self.velocity_projector.parameters():
            param.requires_grad = True
        for param in self.velocity_decoder.parameters():
            param.requires_grad = True
        print("é€Ÿåº¦è§£ç è·¯å¾„å·²è§£å†»")
    
    def unfreeze_seismic_path(self) -> None:
        """è§£å†»åœ°éœ‡è§£ç è·¯å¾„"""
        for param in self.seismic_projector.parameters():
            param.requires_grad = True
        for param in self.seismic_decoder.parameters():
            param.requires_grad = True
        print("åœ°éœ‡è§£ç è·¯å¾„å·²è§£å†»")


class QuantizedUBDiff(nn.Module):
    """é‡åŒ–ç‰ˆæœ¬çš„UB-Diffæ¨¡å‹
    
    ç”¨äºæ ‘è“æ´¾éƒ¨ç½²çš„çº¯ç”Ÿæˆæ¨¡å‹ï¼ˆä¸åŒ…å«ç¼–ç å™¨ï¼‰
    """
    
    def __init__(self,
                 encoder_dim: int = 512,
                 velocity_channels: int = 1,
                 seismic_channels: int = 5,
                 dim_mults: Tuple[int, ...] = (1, 2, 4, 8),
                 time_steps: int = 256,
                 time_scale: int = 1,
                 objective: str = 'pred_v',
                 quantize_diffusion: bool = True,
                 quantize_decoder: bool = True):
        """
        Args:
            encoder_dim: æ½œåœ¨ç©ºé—´ç»´åº¦
            velocity_channels: é€Ÿåº¦åœºé€šé“æ•°
            seismic_channels: åœ°éœ‡æ•°æ®é€šé“æ•°
            dim_mults: U-Netç»´åº¦å€æ•°
            time_steps: æ‰©æ•£æ—¶é—´æ­¥æ•°
            time_scale: æ—¶é—´ç¼©æ”¾å› å­
            objective: æ‰©æ•£ç›®æ ‡å‡½æ•°
            quantize_diffusion: æ˜¯å¦é‡åŒ–æ‰©æ•£æ¨¡å‹
            quantize_decoder: æ˜¯å¦é‡åŒ–è§£ç å™¨
        """
        super(QuantizedUBDiff, self).__init__()
        
        self.encoder_dim = encoder_dim
        self.quantize_diffusion = quantize_diffusion
        self.quantize_decoder = quantize_decoder
        
        # é‡åŒ–/åé‡åŒ–å±‚
        self.quant = quant.QuantStub()
        self.dequant = quant.DeQuantStub()
        
        # 1D U-Netç”¨äºæ‰©æ•£
        self.unet = Unet1D(
            dim=encoder_dim,
            channels=1,
            dim_mults=dim_mults
        )
        
        # æ‰©æ•£è¿‡ç¨‹
        betas = cosine_beta_schedule(timesteps=time_steps)
        self.diffusion = GaussianDiffusion1DDefault(
            model=self.unet,
            seq_length=encoder_dim,
            betas=betas,
            time_scale=time_scale,
            objective=objective,
            use_wandb=False
        )
        
        # é‡åŒ–è§£ç å™¨
        self.decoder = QuantizedDecoder(
            encoder_dim=encoder_dim,
            velocity_channels=velocity_channels,
            seismic_channels=seismic_channels,
            quantize_velocity=quantize_decoder,
            quantize_seismic=quantize_decoder
        )
        
    def sample_latent(self, batch_size: int, device: torch.device) -> torch.Tensor:
        """ä»æ‰©æ•£è¿‡ç¨‹é‡‡æ ·æ½œåœ¨è¡¨ç¤º
        
        Args:
            batch_size: æ‰¹æ¬¡å¤§å°
            device: è®¾å¤‡
            
        Returns:
            é‡‡æ ·çš„æ½œåœ¨è¡¨ç¤º (B, encoder_dim)
        """
        # ä»æ‰©æ•£æ¨¡å‹é‡‡æ ·
        z = self.diffusion.sample(batch_size)  # (B, 1, encoder_dim)
        z = z.squeeze(1)  # (B, encoder_dim)
        return z
    
    def generate(self, batch_size: int, device: torch.device) -> Tuple[torch.Tensor, torch.Tensor]:
        """ç”Ÿæˆæ–°çš„é€Ÿåº¦åœºå’Œåœ°éœ‡æ•°æ®
        
        Args:
            batch_size: æ‰¹æ¬¡å¤§å°
            device: è®¾å¤‡
            
        Returns:
            (velocity, seismic): ç”Ÿæˆçš„é€Ÿåº¦åœºå’Œåœ°éœ‡æ•°æ®
        """
        # é‡‡æ ·æ½œåœ¨è¡¨ç¤º
        z = self.sample_latent(batch_size, device)
        
        # é‡å¡‘ä¸ºè§£ç å™¨æœŸæœ›çš„æ ¼å¼
        z = z.view(batch_size, -1, 1, 1)
        
        # è§£ç 
        velocity, seismic = self.decoder(z)
        
        return velocity, seismic
    
    def forward(self, z: Optional[torch.Tensor] = None, 
                batch_size: Optional[int] = None) -> Tuple[torch.Tensor, torch.Tensor]:
        """å‰å‘ä¼ æ’­ï¼ˆç”¨äºå¯¼å‡ºï¼‰
        
        Args:
            z: å¯é€‰çš„æ½œåœ¨è¡¨ç¤ºè¾“å…¥
            batch_size: å¦‚æœzä¸ºNoneï¼Œç”Ÿæˆçš„æ‰¹æ¬¡å¤§å°
            
        Returns:
            (velocity, seismic): ç”Ÿæˆçš„æ•°æ®
        """
        if z is None:
            if batch_size is None:
                raise ValueError("å¿…é¡»æä¾›zæˆ–batch_size")
            device = next(self.parameters()).device
            
            # ä½¿ç”¨æ‰©æ•£æ¨¡å‹é‡‡æ ·
            z = self.diffusion.sample(batch_size)  # ä½¿ç”¨å†…ç½®é‡‡æ ·æ–¹æ³•
            z = z.squeeze(1) if z.dim() > 2 else z
        
        # é‡å¡‘å¹¶è§£ç 
        z = z.view(z.shape[0], -1, 1, 1)
        velocity, seismic = self.decoder(z)
        
        return velocity, seismic
    
    def load_pretrained_weights(self, checkpoint_path: str) -> None:
        """ä»é¢„è®­ç»ƒæ¨¡å‹åŠ è½½æƒé‡
        
        Args:
            checkpoint_path: æ£€æŸ¥ç‚¹è·¯å¾„
        """
        print(f"åŠ è½½é¢„è®­ç»ƒæƒé‡: {checkpoint_path}")
        checkpoint = torch.load(checkpoint_path, map_location='cpu', weights_only=False)
        
        # å¤„ç†ä¸åŒçš„æ£€æŸ¥ç‚¹æ ¼å¼
        if 'model' in checkpoint:
            state_dict = checkpoint['model']
        elif 'state_dict' in checkpoint:
            state_dict = checkpoint['state_dict']
        else:
            state_dict = checkpoint
        
        # åŠ è½½æ‰©æ•£æ¨¡å‹æƒé‡
        diffusion_dict = {}
        for key, value in state_dict.items():
            if key.startswith('diffusion.') or key.startswith('unet.'):
                diffusion_dict[key] = value
        
        # åŠ è½½è§£ç å™¨æƒé‡
        decoder_dict = {}
        for key, value in state_dict.items():
            if 'decoder' in key or 'projector' in key:
                # è°ƒæ•´é”®åä»¥åŒ¹é…æ–°ç»“æ„
                new_key = key.replace('dual_decoder.', 'decoder.')
                decoder_dict[new_key] = value
        
        # åº”ç”¨æƒé‡
        self.load_state_dict({**diffusion_dict, **decoder_dict}, strict=False)
        print("é¢„è®­ç»ƒæƒé‡åŠ è½½å®Œæˆ")
    
    def apply_improved_quantization(self, backend: str = 'qnnpack', 
                                  convert_conv1d: bool = True,
                                  use_aggressive_config: bool = True) -> Dict[str, Any]:
        """åº”ç”¨æ”¹è¿›çš„é‡åŒ–ç­–ç•¥
        
        Args:
            backend: é‡åŒ–åç«¯
            convert_conv1d: æ˜¯å¦è½¬æ¢1Då·ç§¯
            use_aggressive_config: æ˜¯å¦ä½¿ç”¨æ¿€è¿›çš„é‡åŒ–é…ç½®
            
        Returns:
            é‡åŒ–åˆ†ææŠ¥å‘Š
        """
        print("=== åº”ç”¨æ”¹è¿›çš„é‡åŒ–ç­–ç•¥ ===")
        
        # åˆ†æåŸå§‹æ¨¡å‹
        original_analysis = analyze_model_quantizability(self)
        print(f"åŸå§‹æ¨¡å‹ç»Ÿè®¡:")
        print(f"  æ€»æ¨¡å—æ•°: {original_analysis['total_modules']}")
        print(f"  å¯é‡åŒ–æ¨¡å—æ•°: {original_analysis['quantizable_modules']}")
        print(f"  é‡åŒ–ç‡: {original_analysis['quantization_ratio']:.2%}")
        print(f"  1Då·ç§¯æ•°: {original_analysis['conv1d_modules']}")
        
        # è½¬æ¢1Då·ç§¯
        if convert_conv1d:
            print("\nè½¬æ¢1Då·ç§¯ä¸º2Då·ç§¯...")
            converted_diffusion = convert_conv1d_to_conv2d(self.diffusion)
            converted_unet = convert_conv1d_to_conv2d(self.unet)
            total_converted = converted_diffusion + converted_unet
            print(f"âœ“ æˆåŠŸè½¬æ¢ {total_converted} ä¸ª1Då·ç§¯å±‚")
        
        # è®¾ç½®é‡åŒ–åç«¯
        torch.backends.quantized.engine = backend
        
        # åº”ç”¨é‡åŒ–é…ç½®
        if self.quantize_diffusion:
            if use_aggressive_config:
                print("ä½¿ç”¨æ¿€è¿›çš„é‡åŒ–é…ç½®...")
                # åº”ç”¨æ”¹è¿›çš„é‡åŒ–ç­–ç•¥
                self.diffusion = apply_improved_quantization(
                    self.diffusion, backend=backend, convert_conv1d=False  # å·²ç»è½¬æ¢è¿‡äº†
                )
                self.unet = apply_improved_quantization(
                    self.unet, backend=backend, convert_conv1d=False
                )
            else:
                print("ä½¿ç”¨æ ‡å‡†é‡åŒ–é…ç½®...")
                qconfig = quant.get_default_qat_qconfig(backend)
                self.diffusion.qconfig = qconfig
                self.unet.qconfig = qconfig
                
                # å‡†å¤‡QAT
                self.train()
                quant.prepare_qat(self.diffusion, inplace=True)
                quant.prepare_qat(self.unet, inplace=True)
        
        # åˆ†ææ”¹è¿›åçš„æ¨¡å‹
        improved_analysis = analyze_model_quantizability(self)
        print(f"\næ”¹è¿›åæ¨¡å‹ç»Ÿè®¡:")
        print(f"  æ€»æ¨¡å—æ•°: {improved_analysis['total_modules']}")
        print(f"  å¯é‡åŒ–æ¨¡å—æ•°: {improved_analysis['quantizable_modules']}")
        print(f"  é‡åŒ–ç‡: {improved_analysis['quantization_ratio']:.2%}")
        print(f"  1Då·ç§¯æ•°: {improved_analysis['conv1d_modules']}")
        
        # è®¡ç®—æ”¹è¿›æ•ˆæœ
        if original_analysis['quantization_ratio'] > 0:
            improvement = improved_analysis['quantization_ratio'] / original_analysis['quantization_ratio']
            print(f"\nğŸš€ é‡åŒ–ç‡æ”¹è¿›: {improvement:.1f}x")
        
        return {
            'original': original_analysis,
            'improved': improved_analysis,
            'converted_conv1d': total_converted if convert_conv1d else 0
        }
    
    def prepare_for_qat_training(self, backend: str = 'qnnpack') -> None:
        """ä¸ºQATè®­ç»ƒå‡†å¤‡æ¨¡å‹"""
        print("=== å‡†å¤‡QATè®­ç»ƒ ===")
        
        # åº”ç”¨æ”¹è¿›çš„é‡åŒ–ç­–ç•¥
        self.apply_improved_quantization(
            backend=backend,
            convert_conv1d=True,
            use_aggressive_config=True
        )
        
        # è®¾ç½®è®­ç»ƒæ¨¡å¼
        self.train()
        print("âœ“ æ¨¡å‹å·²å‡†å¤‡å¥½è¿›è¡ŒQATè®­ç»ƒ")
    
    def convert_to_quantized(self) -> 'QuantizedUBDiff':
        """è½¬æ¢ä¸ºé‡åŒ–æ¨¡å‹ï¼ˆç”¨äºéƒ¨ç½²ï¼‰"""
        print("=== è½¬æ¢ä¸ºé‡åŒ–æ¨¡å‹ ===")
        
        # è®¾ç½®è¯„ä¼°æ¨¡å¼
        self.eval()
        
        # è½¬æ¢æ‰©æ•£æ¨¡å‹
        if self.quantize_diffusion:
            if hasattr(self.diffusion, 'qconfig'):
                self.diffusion = quant.convert(self.diffusion, inplace=False)
                print("âœ“ æ‰©æ•£æ¨¡å‹å·²è½¬æ¢ä¸ºé‡åŒ–ç‰ˆæœ¬")
            
            if hasattr(self.unet, 'qconfig'):
                self.unet = quant.convert(self.unet, inplace=False)
                print("âœ“ U-Netå·²è½¬æ¢ä¸ºé‡åŒ–ç‰ˆæœ¬")
        
        # è½¬æ¢è§£ç å™¨
        if self.quantize_decoder:
            if hasattr(self.decoder, 'qconfig'):
                self.decoder = quant.convert(self.decoder, inplace=False)
                print("âœ“ è§£ç å™¨å·²è½¬æ¢ä¸ºé‡åŒ–ç‰ˆæœ¬")
        
        print("ğŸ‰ é‡åŒ–è½¬æ¢å®Œæˆ")
        return self
    
    def get_model_info(self) -> Dict[str, Any]:
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        total_params = sum(p.numel() for p in self.parameters())
        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)
        
        return {
            'total_params': total_params,
            'trainable_params': trainable_params,
            'encoder_dim': self.encoder_dim,
            'quantize_diffusion': self.quantize_diffusion,
            'quantize_decoder': self.quantize_decoder
        }


def create_quantized_model_for_deployment(checkpoint_path: str,
                                        quantize_all: bool = True) -> QuantizedUBDiff:
    """åˆ›å»ºç”¨äºéƒ¨ç½²çš„é‡åŒ–æ¨¡å‹
    
    Args:
        checkpoint_path: é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„
        quantize_all: æ˜¯å¦é‡åŒ–æ‰€æœ‰ç»„ä»¶
        
    Returns:
        å‡†å¤‡éƒ¨ç½²çš„é‡åŒ–æ¨¡å‹
    """
    # åˆ›å»ºæ¨¡å‹
    model = QuantizedUBDiff(
        encoder_dim=512,
        velocity_channels=1,
        seismic_channels=5,
        dim_mults=(1, 2, 4, 8),
        time_steps=256,
        quantize_diffusion=quantize_all,
        quantize_decoder=quantize_all
    )
    
    # åŠ è½½é¢„è®­ç»ƒæƒé‡
    model.load_pretrained_weights(checkpoint_path)
    
    return model 